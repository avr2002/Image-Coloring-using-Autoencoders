{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a44700d2-373a-44d4-a929-290781086c27",
   "metadata": {},
   "source": [
    "<!-- ## Autoencoders -->\n",
    "\n",
    "<h1 align='center'> \n",
    "    <b>\n",
    "        <u>Autoencoders</u>\n",
    "    </b> \n",
    "</h1>\n",
    "\n",
    "**References:**\n",
    "1. [Tensorflow Doc - Into to Autoencoders](https://www.tensorflow.org/tutorials/generative/autoencoder) \n",
    "2. [tds Article by Arden Dertat](https://towardsdatascience.com/applied-deep-learning-part-3-autoencoders-1c083af4d798)\n",
    "3. [Jeremy Jordan - Intro to Autoencoders](https://www.jeremyjordan.me/autoencoders/)\n",
    "3. [Autoencoder Feature Extraction- mlmastery](https://machinelearningmastery.com/autoencoder-for-classification/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb27b47e-f1c6-40dd-8815-38a1fdbb008c",
   "metadata": {
    "tags": []
   },
   "source": [
    "## What are Autoencoders?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6984dd84-e21d-40a2-b084-39f21be9b554",
   "metadata": {},
   "source": [
    "$\\rightarrow \\textbf{An Autoencoder}$ is a neural network model that seeks to learn a compressed representation of an input.\n",
    "\n",
    "$\\rightarrow \\textbf{Autoencoders:}$ are a specific type of feedforward neural networks **where the input is the same as the output.** \n",
    "\n",
    "- They compress the input into a lower-dimensional **code** and then reconstruct the output from this representation. The **code** is a compact ‚Äúsummary‚Äù or ‚Äúcompression‚Äù of the input, also called the **latent-space representation.**\n",
    "\n",
    "- An autoencoder consists of 3 components: **encoder, code, and decoder**\n",
    "    - **The encoder compresses the input and produces the code, the decoder then reconstructs the input only using this code.**\n",
    "\n",
    "<div align='center'>\n",
    "    <img src='images/autoencoders.png' width=400/>\n",
    "    <img src='images/autoencoder_schema1.png' width=600/>\n",
    "</div>\n",
    "\n",
    "- To build an autoencoder we need 3 things: \n",
    "    - **an encoding method, decoding method, and a loss function** to compare the output with the target.\n",
    "    \n",
    "* **"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0a06fa5-eada-44b3-9e1b-9c8c403d9c9f",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Properties of Autoencoders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27656f66-13d1-4995-b0ea-7e5c3720147c",
   "metadata": {},
   "source": [
    "**Autoencoders are mainly a dimensionality reduction (or compression) algorithm** with foll. properties:\n",
    "\n",
    "1. **Data-specific:** Autoencoders are only able to meaningfully compress data similar to what they have been trained on. So we can‚Äôt expect an autoencoder trained on handwritten digits to compress landscape photos.\n",
    "\n",
    "2. **Lossy:** The output of the autoencoder will not be exactly the same as the input, it will be a close but degraded representation. \n",
    "\n",
    "3. **Unsupervised:** Autoencoders are considered an unsupervised learning technique since they don‚Äôt need explicit labels to train on, just simply pass the raw i/p data. But to be more precise they are self-supervised because they generate their own labels from the training data.\n",
    "\n",
    "* **"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72b776c4-7786-4e0f-a910-78f6bddce9dd",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Architechture of Autoencoders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b930eb35-0f2f-4941-b9a7-bf970a080d35",
   "metadata": {},
   "source": [
    "The **autoencoder** architechture aims to re-create the provided input data with minimal error. It is a dimentionality reduction technique similar PCA.\n",
    "\n",
    "So, while training an autoencoder algo. we pass the same input data as the target feature. It's like: \n",
    "\n",
    "$$\\boxed{\\large{\\text{Autoencoder}(X:x, y:x) \\rightarrow \\hat{x} \\text{ , where } \\hat{x} \\sim x}}$$ \n",
    "\n",
    "<div align='center'>\n",
    "    <img src='images/autoencoders_ex.png' width=800/>\n",
    "    <img src='images/autoencoder_schema.png'/>\n",
    "</div>\n",
    "\n",
    "* **\n",
    "\n",
    "- Both the **encoder and decoder** are fully-connected feedforward neural networks.\n",
    "- **Code** is a single layer of an ANN with the dimensionality of our choice.\n",
    "- The number of nodes in the code layer(**code size**) is a hyperparameter that we set before training the autoencoder.\n",
    "\n",
    "<div align='center'>\n",
    "    <img src='images/autoencoders.png' width=600/>\n",
    "</div>\n",
    "\n",
    "Above we can see the architechture of an Autoencoder:\n",
    "- First the input passes through the encoder, which is a fully-connected ANN, to produce the code. The decoder, which has the similar ANN structure, then produces the output only using the code. The goal is to get an output identical with the input.\n",
    "\n",
    ">üóùÔ∏è**Note that the decoder architecture is the mirror image of the encoder.** This is not a requirement but it‚Äôs typically the case. \n",
    ">>The only requirement is the dimensionality of the i/p and o/p needs to be the same. Anything in the middle can be played with. For e.g.: in case of image data, the i/p image shape and o/p shape must be same.\n",
    "\n",
    "<div align='center'>\n",
    "    <img src='images/autoencoders_architecture.png' width=1000/>\n",
    "</div>\n",
    "\n",
    "* **"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c50fe2e-3335-4cea-a862-3c614d0c01f9",
   "metadata": {},
   "source": [
    "### Hyperparameters\n",
    "\n",
    "There are 4 hyperparameters that we need to set before training an autoencoder:\n",
    "\n",
    "- **Code size:** # nodes in the middle layer. Smaller size results in more compression.\n",
    "\n",
    "- **Number of layers:** the autoencoder can be as deep as we like. In the figure above we have 2 layers in both the encoder and decoder.\n",
    "\n",
    "- **Number of nodes per layer:** the autoencoder architecture we‚Äôre working on is called a **stacked autoencoder** since the layers are stacked one after another. \n",
    "    - Usually stacked autoencoders look like a ‚Äúsandwitch‚Äù. The number of nodes per layer decreases with each subsequent layer of the encoder, and increases back in the decoder. \n",
    "    \n",
    "    - Also the decoder is symmetric to the encoder in terms of layer structure. As noted above this is not necessary and we have total control over these parameters.<br></br>\n",
    "\n",
    "- **Loss function:** we either use mean squared error (mse) or binary crossentropy. If the input values are in the range [0, 1] then we typically use crossentropy, otherwise we use the mean squared error. [more details - video](https://youtu.be/xTU79Zs4XKY)\n",
    "\n",
    "\n",
    "**Autoencoders are trained the same way as ANNs via backpropagation.**\n",
    "\n",
    "* **"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60a37e63-25ea-469f-a3fb-3b43a4d42bfd",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Dimentionality Reduction: Autoencoders v/s PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56b5fa63-3911-43d3-a40b-1ec939a82b2e",
   "metadata": {},
   "source": [
    "- Unlike PCA which linearly transforms the data where (most of) the variation in the data can be described with fewer dimensions than the initial data, Autoencoders brings non-linearity to the table which helps in dimentionality reduction of more complex data like images where the spatial structure of the data needs to be also considered.\n",
    "\n",
    "- Neural networks are capable of learning nonlinear relationships, this can be thought of as a more powerful (nonlinear) generalization of PCA. \n",
    "\n",
    "- Whereas PCA attempts to discover a lower dimensional hyperplane which describes the original data, autoencoders are capable of learning nonlinear manifolds (a manifold is defined in simple terms as a continuous, non-intersecting surface). The difference between these two approaches is visualized below.\n",
    "\n",
    "<div align='center'>\n",
    "    <img src='images/autoencoder_pca.png'/>\n",
    "</div>\n",
    "\n",
    "For higher dimensional data, autoencoders are capable of learning a complex representation of the data (manifold) which can be used to describe observations in a lower dimensionality and correspondingly decoded into the original input space.\n",
    "<div align='center'>\n",
    "    <img src='images/autoencoder_LinearNonLinear.png'/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3fa629a-2a79-4b66-856c-9ecc6b59a9e7",
   "metadata": {},
   "source": [
    "## More..\n",
    "- Denoising & Sparse Autoenoders...See the reference links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37d93b1d-8b6d-4310-8d0d-8742e29eb37b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82bfc809-a807-4ac1-909a-69799a94f26e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
